import os
import re
from collections import Counter
from stt_module import transcribe_audio
from emotion_module import classify_emotion
from chat_module import chat_with_gpt
from tts_module import speak_text
from consult_chatbot import consult_reply
import requests  # ìƒë‹¨ importì— ì¶”ê°€
import json
import time


# ì˜ìƒ ì „ìš© ì„œë²„ ì„¤ì •
VIDEO_SERVER_BASE = "http://localhost:3000"   # ë°±ì—”ë“œ ì£¼ì†Œ/í¬íŠ¸
VIDEO_API_PREFIX  = "/api"                    # ë°±ì—”ë“œê°€ /api í”„ë¦¬í”½ìŠ¤ ì“°ë©´ ìœ ì§€, ì•„ë‹ˆë©´ "" ë¡œ

def video_api(path: str) -> str:
    """ì˜ìƒ ì „ìš© API í’€ URL ìƒì„±"""
    return f"{VIDEO_SERVER_BASE}{VIDEO_API_PREFIX}{path}"


#ì•„ì´ëŒ€í™” ë°±ì—°ê²°
def save_message_to_api(text, emotion, mode="VOICE", user_no=1, chat_no=1):
    payload = {
        "content": text,
        "mode": mode,
        "summary": emotion,
        "userNo": user_no,
        "chatNo": chat_no
    }
    headers = {"Content-Type": "application/json"}

    print("ğŸ“¤ ì „ì†¡ payload:", json.dumps(payload, ensure_ascii=False))

    
    response = requests.post(
        "http://localhost:3000/messages/send",
        json=payload,
        headers=headers
    )
    
    if response.status_code in [200, 201]:
        print("âœ… ë©”ì‹œì§€ ì €ì¥ ì„±ê³µ!")
    else:
        print(f"âŒ ë©”ì‹œì§€ ì €ì¥ ì‹¤íŒ¨: {response.status_code}, {response.text}")


#ìƒë‹´ì±—ë´‡ ë°±ì—°ê²°
def save_consult_message_to_api(text, mode="CONSULT", user_no=1, summary=None, server="http://localhost:3000"):
    payload = {"content": text, "mode": mode, "userNo": user_no, "summary": summary}
    headers = {"Content-Type": "application/json"}

    print("ğŸ“¤ ìƒë‹´ payload:", json.dumps(payload, ensure_ascii=False))

    try:
        r = requests.post(f"{server}/chatbot/send", json=payload, headers=headers, timeout=10)
        print("ğŸ” status:", r.status_code, "body:", r.text)  # â† ì¶”ê°€!
        if r.status_code in (200, 201):
            print("âœ… ìƒë‹´ ë©”ì‹œì§€ ì €ì¥ ì„±ê³µ!")
        else:
            print(f"âŒ ìƒë‹´ ë©”ì‹œì§€ ì €ì¥ ì‹¤íŒ¨: {r.status_code}, {r.text}")
    except Exception as e:
        print("âš ï¸ ë„¤íŠ¸ì›Œí¬ ì˜ˆì™¸:", e)



#ìƒë‹´ ì±—ë´‡ í´ë˜ìŠ¤
def run_consult_chat(tone="ë‹´ë°±í•˜ê³  ì˜ˆì˜ ìˆëŠ” ìƒë‹´ í†¤", save=True, user_no=1):
    """
    ë¬¸ì˜ ìƒë‹´ ì±—ë´‡: íŠ¹ì • ì§ˆë¬¸(ì‚¬ìš©ë²•/ë³‘ì›)ë§Œ ëŒ€ì‘.
    - tone: ë‹µë³€ ë§íˆ¬ íŒíŠ¸
    - save: Trueë©´ /messages/send ë¡œ ë¡œê·¸ ì €ì¥(ì˜µì…˜)
    """
    print("ğŸ”¸ ë¬¸ì˜ìƒë‹´ ì±—ë´‡ (ì¢…ë£Œ: exit/quit/q)")
    print(f"ğŸ”¹ tone = {tone} | save_to_db = {save}")

    while True:
        try:
            user_text = input("\nğŸ‘¤ You: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nğŸ‘‹ bye"); break

        if user_text.lower() in {"exit", "quit", "q"}:
            print("ğŸ‘‹ bye"); break
        if not user_text:
            continue

        # ë‹µë³€ ìƒì„± (ë‚´ìš©ì€ ê³ ì •, ë¬¸ì²´ë§Œ ë³€í™˜)
        reply = consult_reply(user_text, tone=tone)

        print(f"ğŸ¤– Bot: {reply}")

        # ì›í•˜ë©´ ë©”ì‹œì§€ ë¡œê·¸ ì €ì¥(ì„ íƒ)
        if save:
            try:
                save_consult_message_to_api(user_text, mode="CONSULT", user_no=user_no)

                time.sleep(1)

                save_consult_message_to_api(reply, mode="BOT", user_no=2)
            except Exception as e:
                print("âš ï¸ ì €ì¥ ì‹¤íŒ¨:", e)


# âœ… ê°ì • ë¦¬í¬íŠ¸ í´ë˜ìŠ¤
class EmotionReport:
    def __init__(self):
        self.emotion_log = []
        self.text_log = []

    def add_turn(self, text):
        self.text_log.append(text)
        emotion = classify_emotion(text)
        self.emotion_log.append(emotion)
        return emotion

    def get_emotion_summary(self):
        total = len(self.emotion_log)
        counts = Counter(self.emotion_log)
        return {
            emotion: round((count / total) * 100, 1)
            for emotion, count in counts.items()
        }

    def get_top_keywords(self, top_n=5):
        all_text = ' '.join(self.text_log).lower()
        words = re.findall(r'\b[ê°€-í£a-zA-Z]+\b', all_text)
        stopwords = set(['ê·¸ë¦¬ê³ ', 'ê·¸ë˜ì„œ', 'í•˜ì§€ë§Œ', 'ê·¸ëƒ¥', 'ë‚˜ëŠ”', 'ë„ˆëŠ”', 'ì´ê±´', 'ì €ê±´', 'ë­ì§€', 'ì´ê²Œ', 'ì €ê²Œ', 'ê²ƒ'])
        filtered = [w for w in words if w not in stopwords]
        return [word for word, _ in Counter(filtered).most_common(top_n)]

    def generate_parenting_tip(self):
        emotion_summary = self.get_emotion_summary()
        top_keywords = self.get_top_keywords()

        prompt = f"""
        ë‹¹ì‹ ì€ ì•„ë™ ì‹¬ë¦¬ ì „ë¬¸ê°€ì´ì ë¶€ëª¨ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ë‹¤ìŒì€ ì•„ì´ì™€ì˜ ëŒ€í™”ì—ì„œ ë¶„ì„ëœ ê°ì • ìš”ì•½ê³¼ ì£¼ìš” í‚¤ì›Œë“œì…ë‹ˆë‹¤.

        ê°ì • ìš”ì•½: {emotion_summary}
        ì£¼ìš” í‚¤ì›Œë“œ: {', '.join(top_keywords)}

        ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì•„ì´ì˜ ê°ì • ìƒíƒœë¥¼ ì´í•´í•˜ê³ ,
        ë¶€ëª¨ê°€ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì ‘ê·¼í•˜ë©´ ì¢‹ì„ì§€ í•œêµ­ì–´ë¡œ ë”°ëœ»í•˜ê³  ì‹¤ìš©ì ì¸ ìœ¡ì•„ íŒì„ 3~5ì¤„ë¡œ ì•Œë ¤ì£¼ì„¸ìš”.
        """
        return chat_with_gpt(prompt, emotion="neutral")
    
    
# âœ… ìŒì„± ë³´ê³ ì„œ ì‹¤í–‰ í•¨ìˆ˜
def run_emotion_report():
    report = EmotionReport()
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    audio_dir = os.path.join(BASE_DIR, "audio_inputs")

    if not os.path.exists(audio_dir):
        print(f"âŒ ë””ë ‰í† ë¦¬ {audio_dir} ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    audio_files = sorted([f for f in os.listdir(audio_dir) if f.endswith(".wav")],
                         key=lambda x: int(os.path.splitext(x)[0]))

    for filename in audio_files:
        audio_path = os.path.join(audio_dir, filename)
        print(f"\nğŸ¤ íŒŒì¼ [{filename}] ìŒì„± ì¸ì‹ ì¤‘...")
        user_text = transcribe_audio(audio_path)
        print("ğŸ‘¶ ì¸ì‹ëœ í…ìŠ¤íŠ¸:", user_text)
        emotion = report.add_turn(user_text)
        print(f"ğŸ§  ê°ì • ë¶„ì„ ê²°ê³¼: {emotion}")
        reply = chat_with_gpt(user_text, emotion)
        print(f"ğŸ¤– GPT ì‘ë‹µ: {reply}")
        speak_text(reply)
        save_message_to_api(user_text, emotion, user_no=1)
        save_message_to_api(reply, "neutral", user_no=2)

    print("\nğŸ“Š ì „ì²´ ê°ì • ìš”ì•½:")
    for emo, perc in report.get_emotion_summary().items():
        print(f"- {emo}: {perc}%")
    print("\nğŸ”‘ ì£¼ìš” í‚¤ì›Œë“œ:")
    for i, kw in enumerate(report.get_top_keywords(), 1):
        print(f"{i}. {kw}")
    print("\nğŸ‘¨â€ğŸ‘©â€ğŸ‘§ ìœ¡ì•„ ì†”ë£¨ì…˜ ì œì•ˆ:")
    print(report.generate_parenting_tip())

    report = EmotionReport()

    # ğŸ“Œ audio_inputs í´ë” ê²½ë¡œë¥¼ main.py ê¸°ì¤€ìœ¼ë¡œ ì ˆëŒ€ ê²½ë¡œë¡œ ì„¤ì •
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    audio_dir = os.path.join(BASE_DIR, "audio_inputs")

    if not os.path.exists(audio_dir):
        print(f"âŒ ë””ë ‰í† ë¦¬ {audio_dir} ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    # ìˆ«ì ìˆœìœ¼ë¡œ .wav íŒŒì¼ ì •ë ¬
    audio_files = sorted(
        [f for f in os.listdir(audio_dir) if f.endswith(".wav")],
        key=lambda x: int(os.path.splitext(x)[0])
    )

    for filename in audio_files:
        audio_path = os.path.join(audio_dir, filename)
        print(f"\nğŸ¤ íŒŒì¼ [{filename}] ìŒì„± ì¸ì‹ ì¤‘...")

        # 1. ìŒì„± ì¸ì‹
        user_text = transcribe_audio(audio_path)
        print("ğŸ‘¶ ì¸ì‹ëœ í…ìŠ¤íŠ¸:", user_text)

        # 2. ê°ì • ë¶„ì„
        emotion = report.add_turn(user_text)
        print(f"ğŸ§  ê°ì • ë¶„ì„ ê²°ê³¼: {emotion}")

        # 3. GPT ì‘ë‹µ
        reply = chat_with_gpt(user_text, emotion)
        print(f"ğŸ¤– GPT ì‘ë‹µ: {reply}")

        # 4. TTS ì‘ë‹µ ì¶œë ¥
        speak_text(reply)

        # âœ… ë©”ì‹œì§€ ì €ì¥
        save_message_to_api(user_text, emotion, user_no=1)  # ì‚¬ìš©ìì˜ ë©”ì‹œì§€
        save_message_to_api(reply, "neutral", user_no=2)   # GPTì˜ ì‘ë‹µ (ì¤‘ë¦½ ê°ì •ìœ¼ë¡œ ì €ì¥)

    # âœ… ì „ì²´ í†µê³„ ë° ìœ¡ì•„ ì†”ë£¨ì…˜
    print("\nğŸ“Š ì „ì²´ ê°ì • ìš”ì•½:")
    for emo, perc in report.get_emotion_summary().items():
        print(f"- {emo}: {perc}%")

    print("\nğŸ”‘ ì£¼ìš” í‚¤ì›Œë“œ:")
    for i, kw in enumerate(report.get_top_keywords(), 1):
        print(f"{i}. {kw}")

    print("\nğŸ‘¨â€ğŸ‘©â€ğŸ‘§ ìœ¡ì•„ ì†”ë£¨ì…˜ ì œì•ˆ:")
    print(report.generate_parenting_tip())


#ì˜ìƒ ëŒì–´ì˜¤ê¸°
def fetch_next_video_meta():
    """ë¶„ì„ ëŒ€ê¸° ì˜ìƒ í•˜ë‚˜ì˜ ë©”íƒ€ë°ì´í„° ìš”ì²­: GET /api/videos/next
       ê¸°ëŒ€ ì‘ë‹µ: { success: true, data: { id, signed_url(or url), mime, ... } }"""
    try:
        r = requests.get(video_api("/videos/next"), timeout=10)
        r.raise_for_status()
        j = r.json()
        if j.get("success") and j.get("data"):
            return j["data"]
        print("âŒ ëŒ€ê¸° ì˜ìƒ ì—†ìŒ ë˜ëŠ” ì‹¤íŒ¨:", r.status_code, r.text)
    except Exception as e:
        print("âš ï¸ ì˜ìƒ ë©”íƒ€ ìš”ì²­ ì˜ˆì™¸:", e)
    return None

def download_video(file_url: str, save_path: str):
    """ì„œëª… URL ë˜ëŠ” ê³µê°œ URLë¡œ ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ"""
    with requests.get(file_url, stream=True, timeout=60) as resp:
        resp.raise_for_status()
        with open(save_path, "wb") as f:
            for chunk in resp.iter_content(1024 * 1024):
                if chunk:
                    f.write(chunk)
    return save_path


# âœ… ì˜ìƒ ë³´ê³ ì„œ ì‹¤í–‰ í•¨ìˆ˜
def run_behavior_report(video_path="./recorded_video.mp4"):
    from behavior_report import BehaviorReport

    # (1) ê²½ë¡œ ì§ì ‘ ì•ˆ ì£¼ì—ˆê±°ë‚˜ íŒŒì¼ì´ ì—†ìœ¼ë©´ â†’ ë°±ì—”ë“œì—ì„œ ëŒ€ê¸° ì˜ìƒ í•˜ë‚˜ ë°›ì•„ì„œ ë‹¤ìš´ë¡œë“œ
    if not video_path or not os.path.exists(video_path):
        meta = fetch_next_video_meta()
        if not meta:
            print("â³ ëŒ€ê¸° ì¤‘ì¸ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        file_url = meta.get("signed_url") or meta.get("url")
        vid_id   = meta.get("id", "next")
        tmp_name = f"video_{vid_id}.mp4"
        tmp_path = os.path.join(os.getcwd(), tmp_name)
        print(f"â¬‡ï¸ ë‹¤ìš´ë¡œë“œ: {file_url} -> {tmp_path}")
        video_path = download_video(file_url, tmp_path)

    # (2) ë¶„ì„ ì‹¤í–‰
    b_report = BehaviorReport(video_path)
    b_report.analyze()
    print("\nğŸ¥ í–‰ë™ ë¶„ì„ ë³´ê³ ì„œ:")
    print(b_report.generate_report_text())

    # (ì„ íƒ) ë¶„ì„ ê²°ê³¼ë¥¼ ë°±ì—”ë“œë¡œ ì €ì¥í•˜ê³  ì‹¶ìœ¼ë©´ ì—¬ê¸°ì„œ POST í˜¸ì¶œ ì¶”ê°€ ê°€ëŠ¥
    # requests.post(video_api("/reports"), json={ ... })

#def run_behavior_report(video_path="./recorded_video.mp4"):
#    from behavior_report import BehaviorReport
#    b_report = BehaviorReport(video_path)
#    b_report.analyze()
#    print("\nğŸ¥ í–‰ë™ ë¶„ì„ ë³´ê³ ì„œ:")
#    print(b_report.generate_report_text())


# âœ… CLI ì§„ì…ì  ì¶”ê°€
def cli():
    import argparse, os
    ap = argparse.ArgumentParser()
    ap.add_argument("--mode", choices=["voice", "video", "consult"], required=True)
    ap.add_argument("--video", help="ë¶„ì„í•  mp4 ê²½ë¡œ (video ëª¨ë“œ í•„ìˆ˜)")
    # ìƒë‹´ ì±—ë´‡ìš© ì˜µì…˜
    ap.add_argument("--tone", default="ë‹´ë°±í•˜ê³  ì˜ˆì˜ ìˆëŠ” ìƒë‹´ í†¤",
                    help="ë¬¸ì˜ ì±—ë´‡ ë‹µë³€ í†¤ íŒíŠ¸ (ì˜ˆ: 'ì¹œê·¼í•˜ê³  ê°„ê²°', 'ê³µì‹ì ì´ê³  ê°„ê²°')")
    ap.add_argument("--no-save", action="store_true",
                    help="ë¬¸ì˜ ì±—ë´‡ ëŒ€í™”ë¥¼ /messages/send ë¡œ ì €ì¥(ì˜µì…˜)")
    ap.add_argument("--user-no", type=int, default=1,
                    help="(save ì‚¬ìš© ì‹œ) ì‚¬ìš©ì user_no")
    args = ap.parse_args()

    if args.mode == "voice":
        run_emotion_report()

    elif args.mode == "video":
        if not args.video:
            raise SystemExit("--video ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤. (ì˜ˆ: --video ./uploads/xxx.mp4)")
        if not os.path.isabs(args.video):
            base = os.path.dirname(os.path.abspath(__file__))
            args.video = os.path.normpath(os.path.join(base, args.video))
        run_behavior_report(args.video)

    else:  # consult
        run_consult_chat(tone=args.tone, save=not args.no_save, user_no=args.user_no)


if __name__ == "__main__":
    cli()


# # âœ… ì‹¤í–‰
# if __name__ == "__main__":
# #    main()
#     # ìŒì„± í˜ì´ì§€ â†’ run_emotion_report()
#     run_behavior_report("./ravo_emotion/test.mp4")
#     pass